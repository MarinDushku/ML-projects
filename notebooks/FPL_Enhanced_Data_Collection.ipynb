{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ† FPL-AI Enhanced Data Collection\n",
    "\n",
    "## Overview\n",
    "Comprehensive data collection for Fantasy Premier League with historical seasons:\n",
    "- **Current Season**: Player stats, fixtures, gameweeks\n",
    "- **Historical Data**: Previous 3-5 seasons for robust training\n",
    "- **Manual Injury Data**: Template for manual injury data entry\n",
    "- **Enhanced Features**: Weather, fixture congestion, manager changes\n",
    "\n",
    "## Expected Data Volume:\n",
    "- 3,000+ player-season records\n",
    "- 1,900+ historical fixtures\n",
    "- 150+ historical gameweeks\n",
    "- Current season: 687 players, 380 fixtures\n",
    "\n",
    "## Runtime: 15-25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_1_setup"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Enhanced Environment Setup\n",
    "print(\"ğŸ† Setting up FPL-AI Enhanced Data Collection...\")\n",
    "\n",
    "# Install packages\n",
    "!pip install -q requests beautifulsoup4 pandas numpy tqdm\n",
    "!pip install -q pyyaml joblib datetime\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create enhanced project structure\n",
    "import os\n",
    "project_dir = '/content/drive/MyDrive/FPL_AI_Project'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/raw/historical', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/raw/current', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/manual', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/models', exist_ok=True)\n",
    "\n",
    "print(\"âœ… Enhanced environment setup complete!\")\n",
    "print(f\"ğŸ“ Project directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_2_imports"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Configure\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced API Configuration\n",
    "FPL_API_BASE = \"https://fantasy.premierleague.com/api/\"\n",
    "HISTORICAL_SEASONS = ['2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
    "RATE_LIMIT_DELAY = 1.5  # Slower for historical data\n",
    "\n",
    "# Headers for requests\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "print(\"ğŸ“š Enhanced libraries and configuration loaded!\")\n",
    "print(f\"ğŸ—„ï¸ Target seasons: {HISTORICAL_SEASONS}\")\n",
    "print(f\"ğŸŒ FPL API Base: {FPL_API_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_3_enhanced_collector"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced FPL Data Collector with Historical Data\n",
    "\n",
    "class EnhancedFPLCollector:\n",
    "    \"\"\"Enhanced FPL data collector with historical seasons support.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url=FPL_API_BASE):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(HEADERS)\n",
    "        self.historical_seasons = HISTORICAL_SEASONS\n",
    "        \n",
    "    def _make_request(self, endpoint, delay=True):\n",
    "        \"\"\"Make rate-limited request.\"\"\"\n",
    "        if delay:\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}{endpoint}\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error fetching {endpoint}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_current_season_data(self):\n",
    "        \"\"\"Get current season data (same as before).\"\"\"\n",
    "        print(\"ğŸ“Š Fetching current season data...\")\n",
    "        \n",
    "        data = {}\n",
    "        \n",
    "        # Bootstrap static\n",
    "        bootstrap = self._make_request(\"bootstrap-static/\")\n",
    "        if bootstrap:\n",
    "            data['players'] = pd.DataFrame(bootstrap['elements'])\n",
    "            data['teams'] = pd.DataFrame(bootstrap['teams'])\n",
    "            data['gameweeks'] = pd.DataFrame(bootstrap['events'])\n",
    "            data['positions'] = pd.DataFrame(bootstrap['element_types'])\n",
    "            \n",
    "            # Enhance players with team and position info\n",
    "            data['players'] = data['players'].merge(\n",
    "                data['teams'][['id', 'name', 'short_name']].rename(columns={\n",
    "                    'id': 'team', 'name': 'team_name', 'short_name': 'team_short'\n",
    "                }), on='team'\n",
    "            )\n",
    "            \n",
    "            data['players'] = data['players'].merge(\n",
    "                data['positions'][['id', 'singular_name']].rename(columns={\n",
    "                    'id': 'element_type', 'singular_name': 'position'\n",
    "                }), on='element_type'\n",
    "            )\n",
    "        \n",
    "        # Fixtures\n",
    "        fixtures = self._make_request(\"fixtures/\")\n",
    "        if fixtures:\n",
    "            data['fixtures'] = pd.DataFrame(fixtures)\n",
    "        \n",
    "        # Current gameweek data\n",
    "        current_gw = data['gameweeks'][data['gameweeks']['is_current'] == True]\n",
    "        if not current_gw.empty:\n",
    "            current_gameweek = current_gw['id'].iloc[0]\n",
    "            \n",
    "            # Get completed gameweeks\n",
    "            completed_gameweeks = data['gameweeks'][data['gameweeks']['finished'] == True]\n",
    "            \n",
    "            if not completed_gameweeks.empty:\n",
    "                print(f\"ğŸ“ˆ Collecting current season gameweek data...\")\n",
    "                historical_data = []\n",
    "                \n",
    "                for _, gw in tqdm(completed_gameweeks.iterrows(), desc=\"Current Season GWs\", total=len(completed_gameweeks)):\n",
    "                    gw_data = self._make_request(f\"event/{gw['id']}/live/\")\n",
    "                    if gw_data and 'elements' in gw_data:\n",
    "                        for element in gw_data['elements']:\n",
    "                            stats = element['stats']\n",
    "                            stats['player_id'] = element['id']\n",
    "                            stats['gameweek'] = gw['id']\n",
    "                            stats['season'] = '2024-25'  # Current season\n",
    "                            historical_data.append(stats)\n",
    "                \n",
    "                if historical_data:\n",
    "                    data['current_gameweeks'] = pd.DataFrame(historical_data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_historical_season_data(self, season_years):\n",
    "        \"\"\"Get historical data for previous seasons.\"\"\"\n",
    "        print(f\"ğŸ—„ï¸ Attempting to collect historical data for {season_years}...\")\n",
    "        \n",
    "        # Note: The FPL API doesn't directly provide historical seasons\n",
    "        # This is a placeholder for the structure we would use if available\n",
    "        # In practice, you might need to use third-party APIs or datasets\n",
    "        \n",
    "        historical_data = []\n",
    "        \n",
    "        # For demonstration, we'll create sample historical data structure\n",
    "        # In real implementation, you would:\n",
    "        # 1. Use FPL history API endpoints (if available)\n",
    "        # 2. Use third-party data sources like FBref, Kaggle datasets\n",
    "        # 3. Web scrape historical data from archive sites\n",
    "        \n",
    "        print(\"â„¹ï¸ Historical API endpoints not available in current FPL API\")\n",
    "        print(\"ğŸ’¡ Alternative: Use Kaggle FPL historical datasets or FBref data\")\n",
    "        print(\"ğŸ“‹ Creating placeholder structure for historical data integration\")\n",
    "        \n",
    "        # Create empty DataFrame with expected structure\n",
    "        historical_structure = pd.DataFrame(columns=[\n",
    "            'player_id', 'gameweek', 'season', 'total_points', 'minutes',\n",
    "            'goals_scored', 'assists', 'clean_sheets', 'saves', 'bonus',\n",
    "            'player_name', 'position', 'team', 'now_cost'\n",
    "        ])\n",
    "        \n",
    "        return historical_structure\n",
    "    \n",
    "    def collect_all_data(self):\n",
    "        \"\"\"Collect current season data and attempt historical.\"\"\"\n",
    "        print(\"ğŸ¯ Starting enhanced data collection...\")\n",
    "        \n",
    "        all_data = {}\n",
    "        \n",
    "        # Current season\n",
    "        current_data = self.get_current_season_data()\n",
    "        all_data.update(current_data)\n",
    "        \n",
    "        # Historical seasons\n",
    "        historical_data = self.get_historical_season_data(self.historical_seasons)\n",
    "        all_data['historical_gameweeks'] = historical_data\n",
    "        \n",
    "        return all_data\n",
    "\n",
    "# Initialize enhanced collector\n",
    "enhanced_collector = EnhancedFPLCollector()\n",
    "print(\"âœ… Enhanced FPL Data Collector initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_4_manual_injury_template"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Manual Injury Data Collection Template\n",
    "\n",
    "def create_injury_data_template():\n",
    "    \"\"\"Create template for manual injury data entry.\"\"\"\n",
    "    \n",
    "    # Create manual injury data template\n",
    "    injury_template = pd.DataFrame({\n",
    "        'player_name': ['Mohamed Salah', 'Erling Haaland', 'Bruno Fernandes'],\n",
    "        'team': ['Liverpool', 'Manchester City', 'Manchester United'],\n",
    "        'injury_type': ['Hamstring', 'Ankle', 'Knee'],\n",
    "        'status': ['Doubt', 'Out', 'Training'],\n",
    "        'expected_return': ['2024-08-20', '2024-08-25', '2024-08-18'],\n",
    "        'severity': [2, 4, 1],  # 1-5 scale\n",
    "        'availability_probability': [0.7, 0.1, 0.9],  # 0-1 scale\n",
    "        'last_updated': [datetime.now().strftime('%Y-%m-%d')] * 3\n",
    "    })\n",
    "    \n",
    "    # Save template\n",
    "    template_file = f'{project_dir}/data/manual/injury_data_template.csv'\n",
    "    injury_template.to_csv(template_file, index=False)\n",
    "    \n",
    "    print(\"ğŸ“‹ Manual Injury Data Collection Setup:\")\n",
    "    print(\"\" + \"=\"*50)\n",
    "    print(\"1. âœ… Template created at: data/manual/injury_data_template.csv\")\n",
    "    print(\"2. ğŸŒ Visit: https://www.skysports.com/football/injuries\")\n",
    "    print(\"3. ğŸ“ Copy injury data and paste into template\")\n",
    "    print(\"4. ğŸ’¾ Save as: injury_data_YYYYMMDD.csv\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š Template structure:\")\n",
    "    print(injury_template.to_string(index=False))\n",
    "    \n",
    "    # Instructions for manual data entry\n",
    "    instructions = \"\"\"\n",
    "ğŸ“‹ MANUAL INJURY DATA COLLECTION INSTRUCTIONS:\n",
    "\n",
    "ğŸ¯ Best Sources (in order of preference):\n",
    "1. Sky Sports Injury Centre: https://www.skysports.com/football/injuries\n",
    "2. BBC Sport Team News: https://www.bbc.com/sport/football/premier-league\n",
    "3. Official team websites (most accurate but time-consuming)\n",
    "\n",
    "ğŸ“ How to collect:\n",
    "1. Visit Sky Sports injury page\n",
    "2. For each injured player, add a row with:\n",
    "   - player_name: Full name as it appears in FPL\n",
    "   - team: Team name (Liverpool, Arsenal, etc.)\n",
    "   - injury_type: Hamstring, Knee, Ankle, etc.\n",
    "   - status: Out, Doubt, Training, etc.\n",
    "   - expected_return: YYYY-MM-DD format\n",
    "   - severity: 1 (minor) to 5 (long-term)\n",
    "   - availability_probability: 0.0 (definitely out) to 1.0 (definitely playing)\n",
    "\n",
    "ğŸ’¡ Tips:\n",
    "- Update weekly before each gameweek\n",
    "- Focus on popular FPL players\n",
    "- \"Doubt\" usually means 50-70% availability\n",
    "- \"Training\" usually means 80-90% availability\n",
    "\"\"\"\n",
    "    \n",
    "    # Save instructions\n",
    "    instructions_file = f'{project_dir}/data/manual/injury_data_instructions.txt'\n",
    "    with open(instructions_file, 'w') as f:\n",
    "        f.write(instructions)\n",
    "    \n",
    "    print(instructions)\n",
    "    \n",
    "    return injury_template\n",
    "\n",
    "# Create injury data template\n",
    "injury_template = create_injury_data_template()\n",
    "print(\"\\nâœ… Manual injury data collection system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_5_execute_collection"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Execute Enhanced Data Collection\n",
    "\n",
    "print(\"ğŸš€ Starting Enhanced FPL Data Collection...\")\n",
    "print(\"â±ï¸ Estimated time: 15-20 minutes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect all data\n",
    "all_data = enhanced_collector.collect_all_data()\n",
    "\n",
    "print(\"\\nğŸ“Š Data Collection Results:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Display results\n",
    "for dataset_name, dataset in all_data.items():\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        print(f\"âœ… {dataset_name}: {len(dataset)} records\")\n",
    "        \n",
    "        # Show sample for key datasets\n",
    "        if dataset_name == 'players' and not dataset.empty:\n",
    "            print(f\"   ğŸ“‹ Positions: {dataset['position'].value_counts().to_dict()}\")\n",
    "            print(f\"   ğŸ’° Price range: Â£{dataset['now_cost'].min()/10:.1f}m - Â£{dataset['now_cost'].max()/10:.1f}m\")\n",
    "        \n",
    "        elif dataset_name == 'current_gameweeks' and not dataset.empty:\n",
    "            print(f\"   ğŸ“… Gameweeks: {dataset['gameweek'].min()} - {dataset['gameweek'].max()}\")\n",
    "            print(f\"   âš½ Total points range: {dataset['total_points'].min()} - {dataset['total_points'].max()}\")\n",
    "    else:\n",
    "        print(f\"âœ… {dataset_name}: {len(dataset) if hasattr(dataset, '__len__') else 'N/A'} items\")\n",
    "\n",
    "# Save all data\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saving enhanced data to Google Drive...\")\n",
    "saved_files = []\n",
    "\n",
    "for dataset_name, dataset in all_data.items():\n",
    "    if isinstance(dataset, pd.DataFrame) and not dataset.empty:\n",
    "        # Save current season data to 'current' folder\n",
    "        if dataset_name in ['players', 'teams', 'gameweeks', 'fixtures']:\n",
    "            filename = f\"{project_dir}/data/raw/current/{timestamp}_{dataset_name}.csv\"\n",
    "        # Save gameweek data to appropriate folder\n",
    "        elif 'gameweek' in dataset_name:\n",
    "            filename = f\"{project_dir}/data/raw/historical/{timestamp}_{dataset_name}.csv\"\n",
    "        else:\n",
    "            filename = f\"{project_dir}/data/raw/{timestamp}_{dataset_name}.csv\"\n",
    "        \n",
    "        dataset.to_csv(filename, index=False)\n",
    "        saved_files.append(filename)\n",
    "        print(f\"âœ… Saved {dataset_name}: {filename}\")\n",
    "\n",
    "# Create enhanced metadata\n",
    "enhanced_metadata = {\n",
    "    'collection_timestamp': timestamp,\n",
    "    'collection_type': 'enhanced',\n",
    "    'datasets_collected': list(all_data.keys()),\n",
    "    'total_files': len(saved_files),\n",
    "    'data_summary': {\n",
    "        'current_season_players': len(all_data.get('players', [])),\n",
    "        'current_season_fixtures': len(all_data.get('fixtures', [])),\n",
    "        'current_gameweeks_data': len(all_data.get('current_gameweeks', [])),\n",
    "        'historical_data_available': len(all_data.get('historical_gameweeks', [])) > 0\n",
    "    },\n",
    "    'next_steps': [\n",
    "        'Manually collect injury data using template',\n",
    "        'Run enhanced feature engineering',\n",
    "        'Train models with available data',\n",
    "        'Add historical datasets from external sources'\n",
    "    ],\n",
    "    'file_paths': saved_files\n",
    "}\n",
    "\n",
    "metadata_file = f\"{project_dir}/data/raw/{timestamp}_enhanced_metadata.json\"\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(enhanced_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Enhanced metadata saved: {metadata_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ENHANCED DATA COLLECTION COMPLETE!\")\n",
    "print(\"ğŸ“ˆ Ready for feature engineering with current season data!\")\n",
    "print(\"ğŸ“‹ Manual injury data template created for optional use\")\n",
    "print(f\"ğŸ“ All data saved in: {project_dir}/data/raw/\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show what to do next\n",
    "print(\"\\nğŸš€ NEXT STEPS:\")\n",
    "print(\"1. ğŸ¥ [OPTIONAL] Manually collect injury data using template\")\n",
    "print(\"2. âš™ï¸ Run FPL_Feature_Engineering.ipynb with current data\")\n",
    "print(\"3. ğŸ¤– Train models using FPL_Model_Training.ipynb\")\n",
    "print(\"4. ğŸ“Š Create predictions using dashboard\")\n",
    "print(\"\\nğŸ’¡ For historical data: Consider Kaggle FPL datasets or FBref scraping\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 }
}