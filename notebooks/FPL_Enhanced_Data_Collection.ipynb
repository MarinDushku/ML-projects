{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üèÜ FPL-AI Enhanced Data Collection\n",
    "\n",
    "## Overview\n",
    "Comprehensive data collection for Fantasy Premier League with historical seasons:\n",
    "- **Current Season**: Player stats, fixtures, gameweeks\n",
    "- **Historical Data**: Previous 3-5 seasons for robust training\n",
    "- **Manual Injury Data**: Template for manual injury data entry\n",
    "- **Enhanced Features**: Weather, fixture congestion, manager changes\n",
    "\n",
    "## Expected Data Volume:\n",
    "- 3,000+ player-season records\n",
    "- 1,900+ historical fixtures\n",
    "- 150+ historical gameweeks\n",
    "- Current season: 687 players, 380 fixtures\n",
    "\n",
    "## Runtime: 15-25 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_1_setup"
   },
   "outputs": [],
   "source": [
    "# Cell 1: Enhanced Environment Setup\n",
    "print(\"üèÜ Setting up FPL-AI Enhanced Data Collection...\")\n",
    "\n",
    "# Install packages\n",
    "!pip install -q requests beautifulsoup4 pandas numpy tqdm\n",
    "!pip install -q pyyaml joblib datetime\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create enhanced project structure\n",
    "import os\n",
    "project_dir = '/content/drive/MyDrive/FPL_AI_Project'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/raw/historical', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/raw/current', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/data/manual', exist_ok=True)\n",
    "os.makedirs(f'{project_dir}/models', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Enhanced environment setup complete!\")\n",
    "print(f\"üìÅ Project directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_2_imports"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Import Libraries and Configure\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enhanced API Configuration\n",
    "FPL_API_BASE = \"https://fantasy.premierleague.com/api/\"\n",
    "HISTORICAL_SEASONS = ['2019-20', '2020-21', '2021-22', '2022-23', '2023-24']\n",
    "RATE_LIMIT_DELAY = 1.5  # Slower for historical data\n",
    "\n",
    "# Headers for requests\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "print(\"üìö Enhanced libraries and configuration loaded!\")\n",
    "print(f\"üóÑÔ∏è Target seasons: {HISTORICAL_SEASONS}\")\n",
    "print(f\"üåê FPL API Base: {FPL_API_BASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_3_enhanced_collector"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced FPL Data Collector with Historical Data\n",
    "\n",
    "class EnhancedFPLCollector:\n",
    "    \"\"\"Enhanced FPL data collector with historical seasons support.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url=FPL_API_BASE):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update(HEADERS)\n",
    "        self.historical_seasons = HISTORICAL_SEASONS\n",
    "        \n",
    "    def _make_request(self, endpoint, delay=True):\n",
    "        \"\"\"Make rate-limited request.\"\"\"\n",
    "        if delay:\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(f\"{self.base_url}{endpoint}\", timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error fetching {endpoint}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_current_season_data(self):\n",
    "        \"\"\"Get current season data (same as before).\"\"\"\n",
    "        print(\"üìä Fetching current season data...\")\n",
    "        \n",
    "        data = {}\n",
    "        \n",
    "        # Bootstrap static\n",
    "        bootstrap = self._make_request(\"bootstrap-static/\")\n",
    "        if bootstrap:\n",
    "            data['players'] = pd.DataFrame(bootstrap['elements'])\n",
    "            data['teams'] = pd.DataFrame(bootstrap['teams'])\n",
    "            data['gameweeks'] = pd.DataFrame(bootstrap['events'])\n",
    "            data['positions'] = pd.DataFrame(bootstrap['element_types'])\n",
    "            \n",
    "            # Enhance players with team and position info\n",
    "            data['players'] = data['players'].merge(\n",
    "                data['teams'][['id', 'name', 'short_name']].rename(columns={\n",
    "                    'id': 'team', 'name': 'team_name', 'short_name': 'team_short'\n",
    "                }), on='team'\n",
    "            )\n",
    "            \n",
    "            data['players'] = data['players'].merge(\n",
    "                data['positions'][['id', 'singular_name']].rename(columns={\n",
    "                    'id': 'element_type', 'singular_name': 'position'\n",
    "                }), on='element_type'\n",
    "            )\n",
    "        \n",
    "        # Fixtures\n",
    "        fixtures = self._make_request(\"fixtures/\")\n",
    "        if fixtures:\n",
    "            data['fixtures'] = pd.DataFrame(fixtures)\n",
    "        \n",
    "        # Current gameweek data\n",
    "        current_gw = data['gameweeks'][data['gameweeks']['is_current'] == True]\n",
    "        if not current_gw.empty:\n",
    "            current_gameweek = current_gw['id'].iloc[0]\n",
    "            \n",
    "            # Get completed gameweeks\n",
    "            completed_gameweeks = data['gameweeks'][data['gameweeks']['finished'] == True]\n",
    "            \n",
    "            if not completed_gameweeks.empty:\n",
    "                print(f\"üìà Collecting current season gameweek data...\")\n",
    "                historical_data = []\n",
    "                \n",
    "                for _, gw in tqdm(completed_gameweeks.iterrows(), desc=\"Current Season GWs\", total=len(completed_gameweeks)):\n",
    "                    gw_data = self._make_request(f\"event/{gw['id']}/live/\")\n",
    "                    if gw_data and 'elements' in gw_data:\n",
    "                        for element in gw_data['elements']:\n",
    "                            stats = element['stats']\n",
    "                            stats['player_id'] = element['id']\n",
    "                            stats['gameweek'] = gw['id']\n",
    "                            stats['season'] = '2024-25'  # Current season\n",
    "                            historical_data.append(stats)\n",
    "                \n",
    "                if historical_data:\n",
    "                    data['current_gameweeks'] = pd.DataFrame(historical_data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def get_historical_season_data(self, season_years):\n",
    "        \"\"\"Get historical data for previous seasons.\"\"\"\n",
    "        print(f\"üóÑÔ∏è Attempting to collect historical data for {season_years}...\")\n",
    "        \n",
    "        # Note: The FPL API doesn't directly provide historical seasons\n",
    "        # This is a placeholder for the structure we would use if available\n",
    "        # In practice, you might need to use third-party APIs or datasets\n",
    "        \n",
    "        historical_data = []\n",
    "        \n",
    "        # For demonstration, we'll create sample historical data structure\n",
    "        # In real implementation, you would:\n",
    "        # 1. Use FPL history API endpoints (if available)\n",
    "        # 2. Use third-party data sources like FBref, Kaggle datasets\n",
    "        # 3. Web scrape historical data from archive sites\n",
    "        \n",
    "        print(\"‚ÑπÔ∏è Historical API endpoints not available in current FPL API\")\n",
    "        print(\"üí° Alternative: Use Kaggle FPL historical datasets or FBref data\")\n",
    "        print(\"üìã Creating placeholder structure for historical data integration\")\n",
    "        \n",
    "        # Create empty DataFrame with expected structure\n",
    "        historical_structure = pd.DataFrame(columns=[\n",
    "            'player_id', 'gameweek', 'season', 'total_points', 'minutes',\n",
    "            'goals_scored', 'assists', 'clean_sheets', 'saves', 'bonus',\n",
    "            'player_name', 'position', 'team', 'now_cost'\n",
    "        ])\n",
    "        \n",
    "        return historical_structure\n",
    "    \n",
    "    def collect_all_data(self):\n",
    "        \"\"\"Collect current season data and attempt historical.\"\"\"\n",
    "        print(\"üéØ Starting enhanced data collection...\")\n",
    "        \n",
    "        all_data = {}\n",
    "        \n",
    "        # Current season\n",
    "        current_data = self.get_current_season_data()\n",
    "        all_data.update(current_data)\n",
    "        \n",
    "        # Historical seasons\n",
    "        historical_data = self.get_historical_season_data(self.historical_seasons)\n",
    "        all_data['historical_gameweeks'] = historical_data\n",
    "        \n",
    "        return all_data\n",
    "\n",
    "# Initialize enhanced collector\n",
    "enhanced_collector = EnhancedFPLCollector()\n",
    "print(\"‚úÖ Enhanced FPL Data Collector initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_4_manual_injury_template"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Manual Injury Data Collection Template\n",
    "\n",
    "def create_injury_data_template():\n",
    "    \"\"\"Create template for manual injury data entry.\"\"\"\n",
    "    \n",
    "    # Create manual injury data template\n",
    "    injury_template = pd.DataFrame({\n",
    "        'player_name': ['Mohamed Salah', 'Erling Haaland', 'Bruno Fernandes'],\n",
    "        'team': ['Liverpool', 'Manchester City', 'Manchester United'],\n",
    "        'injury_type': ['Hamstring', 'Ankle', 'Knee'],\n",
    "        'status': ['Doubt', 'Out', 'Training'],\n",
    "        'expected_return': ['2024-08-20', '2024-08-25', '2024-08-18'],\n",
    "        'severity': [2, 4, 1],  # 1-5 scale\n",
    "        'availability_probability': [0.7, 0.1, 0.9],  # 0-1 scale\n",
    "        'last_updated': [datetime.now().strftime('%Y-%m-%d')] * 3\n",
    "    })\n",
    "    \n",
    "    # Save template\n",
    "    template_file = f'{project_dir}/data/manual/injury_data_template.csv'\n",
    "    injury_template.to_csv(template_file, index=False)\n",
    "    \n",
    "    print(\"üìã Manual Injury Data Collection Setup:\")\n",
    "    print(\"\" + \"=\"*50)\n",
    "    print(\"1. ‚úÖ Template created at: data/manual/injury_data_template.csv\")\n",
    "    print(\"2. üåê Visit: https://www.skysports.com/football/injuries\")\n",
    "    print(\"3. üìù Copy injury data and paste into template\")\n",
    "    print(\"4. üíæ Save as: injury_data_YYYYMMDD.csv\")\n",
    "    \n",
    "    print(\"\\nüìä Template structure:\")\n",
    "    print(injury_template.to_string(index=False))\n",
    "    \n",
    "    # Instructions for manual data entry\n",
    "    instructions = \"\"\"\n",
    "üìã MANUAL INJURY DATA COLLECTION INSTRUCTIONS:\n",
    "\n",
    "üéØ Best Sources (in order of preference):\n",
    "1. Sky Sports Injury Centre: https://www.skysports.com/football/injuries\n",
    "2. BBC Sport Team News: https://www.bbc.com/sport/football/premier-league\n",
    "3. Official team websites (most accurate but time-consuming)\n",
    "\n",
    "üìù How to collect:\n",
    "1. Visit Sky Sports injury page\n",
    "2. For each injured player, add a row with:\n",
    "   - player_name: Full name as it appears in FPL\n",
    "   - team: Team name (Liverpool, Arsenal, etc.)\n",
    "   - injury_type: Hamstring, Knee, Ankle, etc.\n",
    "   - status: Out, Doubt, Training, etc.\n",
    "   - expected_return: YYYY-MM-DD format\n",
    "   - severity: 1 (minor) to 5 (long-term)\n",
    "   - availability_probability: 0.0 (definitely out) to 1.0 (definitely playing)\n",
    "\n",
    "üí° Tips:\n",
    "- Update weekly before each gameweek\n",
    "- Focus on popular FPL players\n",
    "- \"Doubt\" usually means 50-70% availability\n",
    "- \"Training\" usually means 80-90% availability\n",
    "\"\"\"\n",
    "    \n",
    "    # Save instructions\n",
    "    instructions_file = f'{project_dir}/data/manual/injury_data_instructions.txt'\n",
    "    with open(instructions_file, 'w') as f:\n",
    "        f.write(instructions)\n",
    "    \n",
    "    print(instructions)\n",
    "    \n",
    "    return injury_template\n",
    "\n",
    "# Create injury data template\n",
    "injury_template = create_injury_data_template()\n",
    "print(\"\\n‚úÖ Manual injury data collection system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cell_5_execute_collection"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Execute Enhanced Data Collection\n",
    "\n",
    "print(\"üöÄ Starting Enhanced FPL Data Collection...\")\n",
    "print(\"‚è±Ô∏è Estimated time: 15-20 minutes\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect all data\n",
    "all_data = enhanced_collector.collect_all_data()\n",
    "\n",
    "print(\"\\nüìä Data Collection Results:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Display results\n",
    "for dataset_name, dataset in all_data.items():\n",
    "    if isinstance(dataset, pd.DataFrame):\n",
    "        print(f\"‚úÖ {dataset_name}: {len(dataset)} records\")\n",
    "        \n",
    "        # Show sample for key datasets\n",
    "        if dataset_name == 'players' and not dataset.empty:\n",
    "            print(f\"   üìã Positions: {dataset['position'].value_counts().to_dict()}\")\n",
    "            print(f\"   üí∞ Price range: ¬£{dataset['now_cost'].min()/10:.1f}m - ¬£{dataset['now_cost'].max()/10:.1f}m\")\n",
    "        \n",
    "        elif dataset_name == 'current_gameweeks' and not dataset.empty:\n",
    "            print(f\"   üìÖ Gameweeks: {dataset['gameweek'].min()} - {dataset['gameweek'].max()}\")\n",
    "            print(f\"   ‚öΩ Total points range: {dataset['total_points'].min()} - {dataset['total_points'].max()}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {dataset_name}: {len(dataset) if hasattr(dataset, '__len__') else 'N/A'} items\")\n",
    "\n",
    "# Save all data\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"\\nüíæ Saving enhanced data to Google Drive...\")\n",
    "saved_files = []\n",
    "\n",
    "for dataset_name, dataset in all_data.items():\n",
    "    if isinstance(dataset, pd.DataFrame) and not dataset.empty:\n",
    "        # Save current season data to 'current' folder\n",
    "        if dataset_name in ['players', 'teams', 'gameweeks', 'fixtures']:\n",
    "            filename = f\"{project_dir}/data/raw/current/{timestamp}_{dataset_name}.csv\"\n",
    "        # Save gameweek data to appropriate folder\n",
    "        elif 'gameweek' in dataset_name:\n",
    "            filename = f\"{project_dir}/data/raw/historical/{timestamp}_{dataset_name}.csv\"\n",
    "        else:\n",
    "            filename = f\"{project_dir}/data/raw/{timestamp}_{dataset_name}.csv\"\n",
    "        \n",
    "        dataset.to_csv(filename, index=False)\n",
    "        saved_files.append(filename)\n",
    "        print(f\"‚úÖ Saved {dataset_name}: {filename}\")\n",
    "\n",
    "# Create enhanced metadata\n",
    "enhanced_metadata = {\n",
    "    'collection_timestamp': timestamp,\n",
    "    'collection_type': 'enhanced',\n",
    "    'datasets_collected': list(all_data.keys()),\n",
    "    'total_files': len(saved_files),\n",
    "    'data_summary': {\n",
    "        'current_season_players': len(all_data.get('players', [])),\n",
    "        'current_season_fixtures': len(all_data.get('fixtures', [])),\n",
    "        'current_gameweeks_data': len(all_data.get('current_gameweeks', [])),\n",
    "        'historical_data_available': len(all_data.get('historical_gameweeks', [])) > 0\n",
    "    },\n",
    "    'next_steps': [\n",
    "        'Manually collect injury data using template',\n",
    "        'Run enhanced feature engineering',\n",
    "        'Train models with available data',\n",
    "        'Add historical datasets from external sources'\n",
    "    ],\n",
    "    'file_paths': saved_files\n",
    "}\n",
    "\n",
    "metadata_file = f\"{project_dir}/data/raw/{timestamp}_enhanced_metadata.json\"\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(enhanced_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìã Enhanced metadata saved: {metadata_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ENHANCED DATA COLLECTION COMPLETE!\")\n",
    "print(\"üìà Ready for feature engineering with current season data!\")\n",
    "print(\"üìã Manual injury data template created for optional use\")\n",
    "print(f\"üìÅ All data saved in: {project_dir}/data/raw/\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show what to do next\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"1. üè• [OPTIONAL] Manually collect injury data using template\")\n",
    "print(\"2. ‚öôÔ∏è Run FPL_Feature_Engineering.ipynb with current data\")\n",
    "print(\"3. ü§ñ Train models using FPL_Model_Training.ipynb\")\n",
    "print(\"4. üìä Create predictions using dashboard\")\n",
    "print(\"\\nüí° For historical data: Consider Kaggle FPL datasets or FBref scraping\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 }
}